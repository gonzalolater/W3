# Transformer

## Data

The tokenizer has normal and fast version. The fast version is implemented by rust programming language and binding in the Python language. The tokenizer is an independent Python package under the umbrella of hugging face organization.

The tokenizer can be pretrained. The text is read from the file. The text is tokenized and convert to identity representation. Each line can be a complete record in the data set file. The language model has the request for data arrangement, structure, format and size.

The file lock is a community package for locking file. The torch library has the utility definition for data class. The training arguments are described by a data class which has the concise fields. The total training data is composed of features, data set and examples.

Each consise data has its own data format and rules. The different section is extracted according to its specific rules. A DataCollator is a function that takes a list of samples from a Dataset and collate them into a batch, as a dictionary of PyTorch/TensorFlow tensors or NumPy arrays.

The function and control flow are utilized to perform computation. The data is processed according to the rule.The memory object is leveraged to hold state daya. Different data processor are added to support different cases. The base class is used as interface template.

The `csv`, `dataclass` and `typing` packages are imported at the head of `util.py` file. The three dots are used to do relative module reference in the grandparent package. The data class is a decorator of annotating the class to be data purpose class. The data file is used to fill all kinds of memory data.
